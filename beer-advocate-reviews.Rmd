---
title: "Analysis of Beer Reviews"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(scales)
theme_set(theme_minimal())
# Read in the raw data
reviews_raw <- read_csv("Data/beerreviews/beer_reviews.csv")
```




### Data Exploration before Analysis
```{r}
# 5840 different breweries represented in the dataset: Sam Adams the largest
reviews_raw%>%
  count(brewery_id, brewery_name, sort = TRUE)

#  66055 different beers reviewed. Lots of Stone, Sierra Nevada representation
reviews_raw%>%
  count(beer_beerid, beer_name, brewery_name, sort = TRUE)

# removed beers without abv listings and then see how many different beers
# breweries are producing. 
# Also tried to see how that compared to the mean/median # of beers made, but
# that doesn't seem particularly useful
reviews_raw %>%
  filter(!is.na(beer_abv))%>%
  count(brewery_name, beer_name, sort = TRUE)%>%
  count(brewery_name, sort = TRUE)%>%
  mutate(avg_num_beers_made = mean(nn),
         median_num_beers_made = median(nn),
         fraction = nn/avg_num_beers_made)%>%
  arrange(desc(fraction))

# Plotting distribution of 5 different review categories
reviews_raw %>%
  select(starts_with('review'), -review_profilename)%>%
  gather(review_type, score, -review_time)%>%
  ggplot(aes(score))+
  geom_histogram()+
  facet_wrap(~review_type)+
  scale_y_continuous(labels = number_format())

# 104 styles of beer(some seem very close to the same thing)
reviews_raw%>%
  count(beer_style, sort = TRUE)

# Looking at how average score varies by style of beer.
avg_score_by_style <- reviews_raw%>%
  group_by(beer_style)%>%
  summarise(avg_score = mean(review_overall),
            reviews = n())%>%
  ungroup()%>%
  arrange(desc(avg_score))

library(broom)
# This first approach groups by the unique beers and styles--so it averages
# the score of each individual beer and then our final estimates are an average of 
# all the unique beers in that beer style. This givens a lot of weight to beers with
# few reviews

# Have to group differently to show conf intervals for scores of beer styles
by_beerid <- reviews_raw %>%
  group_by(beer_beerid, beer_style)%>%
  summarise(reviews = n(),
            avg_score = mean(review_overall))%>%
  ungroup()%>%
  arrange(desc(reviews))

# generate confidence intervals for styles of beer
beer_style_conf_int <- by_beerid%>%
  add_count(beer_style)%>%
  # filters to beers styles with greater than 250 different beers reviewed
  # may also want to filter to only include specific beers with at least X number of reviews
  filter(n >=250)%>%
  nest(-beer_style)%>%
  mutate(model = map(data, ~t.test(.$avg_score)))%>%
  unnest(map(model, tidy))

beer_style_conf_int%>%
  mutate(beer_style = fct_reorder(beer_style, estimate))%>%
  top_n(25, estimate)%>%
  ggplot(aes(estimate, beer_style))+
  geom_point()+
  geom_errorbarh(aes(xmin = conf.low,
                     xmax = conf.high))+
  labs(x = "Average overall review score",
       y = "Beer Style",
       title = "Average review score of different styles of beer",
       subtitle = "Beers grouped by unique beers first, then averaged at the style level")

# This approach creates a unique id for each review(since there isn't one in the dataset)
# and then it groups by beer style. This means I keep all individual reviews and those
# unique beers with very few reviews don't get as much weight. This seems like a 
# really clunky way of doing this, so I am probably missing a much simpler way.

#Assign a unique identifier to each review first
by_reviewid <- reviews_raw %>%
  mutate(unique_id = 1:nrow(reviews_raw))%>%
  mutate(avg_score = review_overall)%>%
  select(unique_id, beer_style, avg_score)

# generate the conf intervals on the reviewid level data
beer_style_conf_int_by_reviewid <- by_reviewid%>%
  add_count(beer_style)%>%
  # filters to beers styles with greater than 250 different beers reviewed
  # may also want to filter to only include specific beers with at least X number of reviews
  filter(n >=250)%>%
  nest(-beer_style)%>%
  mutate(model = map(data, ~t.test(.$avg_score)))%>%
  unnest(map(model, tidy))

# plot
beer_style_conf_int_by_reviewid%>%
  mutate(beer_style = fct_reorder(beer_style, estimate))%>%
  top_n(25, estimate)%>%
  ggplot(aes(estimate, beer_style))+
  geom_point()+
  geom_errorbarh(aes(xmin = conf.low,
                     xmax = conf.high))+
  labs(x = "Average overall review score",
       y = "Beer Style",
       title = "Average review score of different styles of beer",
       subtitle = "Averaged directly from the individual review level")

reviews_raw %>%
  filter(!is.na(beer_abv), beer_abv < 3)%>%
  ggplot(aes(beer_abv))+
  geom_histogram()+
  geom_vline(aes(xintercept = median(beer_abv)), color = 'red')
```

