---
title: "Strings"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```

Combining strings

```{r}
string1 <- "This is a string"
string2 <- 'If I want to include a "quote" inside a string, I use single quotes'

x <- c("abc", NA)
x

str_c("|-", x, "-|")
str_c("|-", str_replace_na(x), "-|")
str_c("prefix-", c("a", "b", "c"), "-suffix")

name <- "Adam"
time_of_day <- "morning"
birthday <- TRUE

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)

str_c(c("x", "y", "z"), collapse = ", ")

str_c(c("x", "y", "z"))
```

Subsetting strings

```{r}
x <- c("ApPle", "BanAna", "PeAr")
str_sub(x, 1, 3)
str_sub(x, -3, -1)

str_sub("a", 1, 5)

str_sub(x, 1, 5) <- str_to_lower(str_sub(x, 1, 5))
str_to_lower(x)
x
```

Write a function that turns (e.g.) a vector c("a", "b", "c") into the string a, b, and c. Think carefully about what it should do if given a vector of length 0, 1, or 2.
```{r}
x <- c("a", "b", "c", "d")
y <- c()
z <- c("z")
b <- c("a", "b")
str_c(x, collapse = ",")

collapser <- function(x){
  x_len <- length(x)
  if(x_len <= 1){
    str_c(x, collapse = "")
  }
  else if(x_len == 2){
    str_c(x, collapse = " and ")
  }
  else {
    first_part <- str_c(x[seq_len(x_len - 1)], collapse = ", ")
    
    last_part <- str_c("and", x[[x_len]], sep = " ")
    
    str_c(first_part, last_part, sep = ", ")
    
  }
}
```

Regular Expressions

```{r}
x <- c("apple", "banana", "pear")

str_view(x, "an")

# . matches any character(except new line)
str_view(x, ".a.")

dot <- "\\."
writeLines(dot)

str_view(c("abc", "a.c", "bef"), "a\\.c")

x <- "a\\b"
writeLines(x)

str_view(x, "\\\\")

x <- "\"'\\"

str_view(x, "\"'\\\\", match = TRUE)

x <- "\\..\\..\\.."

str_view(c(".a.b.c", ".a.b", "....."), c("\\..\\..\\.."))
```


Anchors
```{r}
x <- c("apple", "banana", "pear")

str_view(x, "^a")
str_view(x, "a$")


x <- "$^$"
str_view(x, "^\\$\\^\\$$")
```

Given the corpus of common words in stringr::words, create regular expressions that find all words that:

Start with “y”.
End with “x”
Are exactly three letters long. (Don’t cheat by using str_length()!)
Have seven letters or more.
Since this list is long, you might want to use the match argument to str_view() to show only the matching or non-matching words.

```{r}
stringr::words

str_view(stringr::words, "^y", match = TRUE)

str_view(stringr::words, "x$", match = TRUE)

str_view(stringr::words, "^[a-z][a-z][a-z]$", match = TRUE)
str_view(stringr::words, "^...$", match = TRUE)

str_view(stringr::words, "^[a-z][a-z][a-z][a-z][a-z][a-z][a-z]", match = TRUE)
str_view(stringr::words, ".......", match = TRUE)
```

## Character classes and alternatives
- \d matches any digit
- \s matches any whitespace
- [abc] matches a, b, or c
- [^abc] matches anything except a, b, or c


```{r}
str_view(c("abc", "a.c", "a*c", "a c"), "a[.]c")

str_view(c("abc", "a.c", "a*c", "a c"), ".[*]c")

str_view(c("abc", "a.c", "a*c", "a c"), "a[ ]")

str_view(c("grey", "gray"), "gr(e|a)y")
str_view(c("grey", "gray"), "gre|ay")
```

Create regular expressions to find all words that:

Start with a vowel.

That only contain consonants. (Hint: thinking about matching “not”-vowels.)

End with ed, but not with eed.

End with ing or ise.

```{r}
str_subset(stringr::words, "^[aeiou]")

str_subset(stringr::words, "^[^aeiou]+$")


str_subset(stringr::words, "[^e][e]d$")

str_subset(stringr::words, "i(ng|se)$")
```

Empirically verify the rule “i before e except after c”.

```{r}
str_subset(stringr::words, "cie")
str_subset(stringr::words, "ei")

str_subset(stringr::words, "(cei|[^c]ie)")

str_subset(stringr::words, "cie|[^c]ei")

```

Is “q” always followed by a “u”?
```{r}
str_subset(stringr::words, "(qu|q[^u])")
str_subset(stringr::words, "q[^u]")

```

Write a regular expression that matches a word if it’s probably written in British English, not American English.

```{r}
str_subset(c("color", "colour"), "ou")
str_subset(stringr::words, "ou|ae|oe|ise$|yse$")
```

Create a regular expression that will match telephone numbers as commonly written in your country.
```{r}
number <- "555-123-4567"

str_view(number, "\\d{3}-\\d{3}-\\d{4}")
```


## Repetition

- ? : 0 or 1
- + : 1 or more
- * : 0 or more

- {n} : exactly n
- {n,} : n or more
- {,m} : at most m
- {n,m} : between n and m

Describe the equivalents of ?, +, * in {m,n} form.
? = {0, 1}
+ = {1, }
* = {0, }


Describe in words what these regular expressions match: (read carefully to see if I’m using a regular expression or a string that defines a regular expression.)

- ^.*$ -- matches any string
- "\\{.+\\}" -- any string with curly brackets around at least one character
- \d{4}-\d{2}-\d{2} -- 4 digits followed by a dash, followed by 2 digits, then a dash, then 2 more digits
- "\\\\{4}" -- 4 backslashes


Create regular expressions to find all words that:

Start with three consonants.
Have three or more vowels in a row.
Have two or more vowel-consonant pairs in a row.
```{r}
str_view(stringr::words, "^[^aeiou]{3}", match = TRUE)

str_view(stringr::words, "[aeiou]{3,}", match = TRUE)

str_view(stringr::words, "[aeiou][^aeiou]{2, }", match = TRUE)
```

Describe, in words, what these expressions will match:

- (.)\1\1 -- same character 3 times--though in R I think they should be double backslashes
- "(.)(.)\\2\\1" -- 2 characters then a repeat of the 2nd then a repeat of the first
- (..)\1 -- 2 characters and a repeat of those characters
- "(.).\\1.\\1" -- any character followed by any character then a repeat of the 1st character followed by any character and a repeat of the 1st
again 
- "(.)(.)(.).*\\3\\2\\1" -- any 3 characters, followed by 0 or more of any character, then the first 3 characters reversed

Construct regular expressions to match words that:

Start and end with the same character.
```{r}
str_view(stringr::words, "^(.).*\\1$", match = TRUE)
str_view(stringr::words, "^(.)((.*\\1$)|\\1?$)", match = TRUE)
```

Contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice.)
```{r}
str_view(stringr::words, "(..)(.*\\1)|\\1", match = TRUE) # this doesn't restrict to letters
str_view(stringr::words, "([A-Za-z][A-Za-z]).*\\1", match = TRUE) # this does restrict to just letters
```

Contain one letter repeated in at least three places (e.g. “eleven” contains three “e”s.)
```{r}
str_view(stringr::words, "(.).*\\1.*\\1", match = TRUE)
```

## Detect matches

Use str_detect() to see if a character vector matches a pattern
```{r}
x <- c("apple", "banana", "pear")

str_detect(x, "e")

# how many words start with t
sum(str_detect(stringr::words, "^t"))

#what proportion of words end with a vowel?
mean(str_detect(stringr::words, "[aeiou]$"))
```

```{r}
df <- tibble(
  word = stringr::words,
  i = seq_along(word))
)

df %>%
  filter(str_detect(word, "x$"))

df %>%
  mutate(
    vowels = str_count(word, "[aeoiu]"),
    consonants = str_count(word, "[^aeiou]")
  )
```

For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple str_detect() calls.

Find all words that start or end with x.
```{r}
str_view(stringr::words, "^x|x$", match = TRUE)

stringr::words[str_detect(stringr::words, "^x|x$")]
```

Find all words that start with a vowel and end with a consonant.
```{r}
words <- stringr::words
str_view(words, "^[aeoiu].*[^aeoiu]$", match = TRUE)

start_vowel <- str_detect(words, "^[aeoiu]")
end_consonant <- str_detect(words, "[^aeoiu]$")
words[start_vowel & end_consonant]
```

Are there any words that contain at least one of each different vowel?
```{r}
str_view(words, ) # no idea

a <- str_detect(words, "[a]")
e <- str_detect(words, "[e]")
i <- str_detect(words, "[i]")
o <- str_detect(words, "[o]")
u <- str_detect(words, "[u]")

words[a&e&i&o&u]
```

What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator?)
```{r}
vowels <- str_count(words, "[aeoiu]")
# most vowels
words[which(vowels == max(vowels))]

#highest proportion of vowels
prop_vowels <- str_count(words, "[aeoiu]")/str_length(words)
words[which(prop_vowels == max(prop_vowels))]

```


## Extract matches

```{r}
sentences <- stringr::sentences

colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c(colours, collapse = "|")

has_colour <- str_subset(sentences, colour_match)

matches <- str_extract(has_colour, colour_match)
head(matches)

more <- sentences[str_count(sentences, colour_match) > 1]
str_view_all(more, colour_match)

str_extract_all(more, colour_match)

str_extract_all(more, colour_match, simplify = TRUE)
```

In the previous example, you might have noticed that the regular expression matched “flickered”, which is not a colour. Modify the regex to fix the problem.

```{r}
colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c("\\b(", str_c(colours, collapse = "|"), ")\\b")

str_subset(sentences, colour_match)
```

From the Harvard sentences data, extract:

The first word from each sentence.
```{r}
str_extract(sentences, "[A-Za-z][A-Za-z']*")
```

All words ending in ing.
```{r}
has_ing <- str_detect(sentences, "\\b[A-Za-z]+ing\\b")
unique(unlist(str_extract_all(sentences[has_ing], "\\b[A-Za-z]+ing\\b")))

```

All plurals.
Not sure.

## Grouped Matches

```{r}
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  str_subset(noun)%>%
  head(10)

has_noun %>%
  str_extract(noun)

has_noun %>%
  str_match(noun)

tibble(sentence = sentences)%>%
  tidyr::extract(
    sentence, c("article", "noun"), "(a|the) ([^ ]+)",
    remove = FALSE
  )
```

Find all words that come after a “number” like “one”, “two”, “three” etc. Pull out both the number and the word.

```{r}
numbers <- "\\b(one|two|three|four|five|six|seven|eight|nine|ten) +(\\w+)"
sentences %>%
  str_subset(numbers)

tibble(sentence = sentences)%>%
  tidyr::extract(
    sentence, c("number", "word"), "\\b(one|two|three|four|five|six|seven|eight|nine|ten) +(\\w+)",
    remove = FALSE
  )
```

Find all contractions. Separate out the pieces before and after the apostrophe.

```{r}
contracts <- "[A-Za-z]+'[a-z]+"
sentences %>%
  str_subset(contracts)

tibble(sentence = sentences)%>%
  tidyr::extract(
    sentence, c("first", "second"), "([A-Za-z]+)'([a-z]+)",
    remove = FALSE
  )

```

## Replacing Matches

```{r}
x <- c("apple", "banana", "pear")
str_replace(x, "[aeoiu]", "-")
str_replace_all(x, "[aeoiu]", "-")

x <- c("1 house", "2 cars", "3 people")
str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))

#flips the order of the 2nd and 3rd words
sentences %>%
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2")
```

Replace all forward slashes in a string with backslashes.
```{r}
slashes <- "This/sentence/has/a/lot/of/slashes."
str_replace_all(slashes, "/", "\\\\")

```

Implement a simple version of str_to_lower() using replace_all().
```{r}
test <- "This SEntence Is very Uppercase."
replacements <- c(
  "A" = "a", "B" = "b", "C" = "c", "D" = "d", "E" = "e",
  "F" = "f", "G" = "g", "H" = "h", "I" = "i", "J" = "j",
  "K" = "k", "L" = "l", "M" = "m", "N" = "n", "O" = "o",
  "P" = "p", "Q" = "q", "R" = "r", "S" = "s", "T" = "t",
  "U" = "u", "V" = "v", "W" = "w", "X" = "x", "Y" = "y",
  "Z" = "z"
)
str_replace_all(test, pattern = replacements)
```

Switch the first and last letters in words. Which of those strings are still words?
```{r}
intersect(str_replace_all(words, "([A-Za-z])(.*)([a-z])$", "\\3\\2\\1"), words)

```


##Splitting

```{r}
sentences <- stringr::sentences

sentences %>%
  head(5)%>%
  str_split(" ")

"a|b|c|d"%>%
  str_split("\\|")%>%
  .[[1]]

# simplify = True forces it to return a matrix
sentences %>%
  head(5)%>%
  str_split(" ", simplify = TRUE)

# specifying a maximum number of pieces
fields <- c("Name: Hadley", "Country: NZ", "Age: 35")

fields %>%
  str_split(": ", n = 2, simplify = TRUE)

#can split by boundary too
x <- "This is a sentence. This is another sentence."
str_view_all(x, boundary("character"))

str_split(x, " ")[[1]]
str_split(x, boundary("word"))[[1]]
```


Split up a string like "apples, pears, and bananas" into individual components.
```{r}
x <- c("apples, pears, and bananas")

str_split(str_replace_all(x, ",", ""), " ")[[1]]
```

Why is it better to split up by boundary("word") than " "?
Exercise 1 above is perfect example. It's difficult to  split phrases with complicated puncuation using " ", while
boundary is more sophisticated by default.
```{r}
str_split(x, boundary("word"))[[1]]
```

What does splitting with an empty string ("") do? Experiment, and then read the documentation.
```{r}
str_split(x, "")
```
"" splits by character--which you can do using boundary("character")

```{r}
str_locate(x, "apple")
```

## Other types of patterns
When you are matching patterns that are strings, they are automatically wrapped in a regex() call.
You can use other arguments of regex() to control details of match.

How would you find all strings containing \ with regex() vs. with fixed()?
```{r}
x <- c("this\\has\\slashes", "this\\also\\has\\slashes")
str_view_all(x, regex("\\\\"))
str_view_all(x, fixed("\\"))
```

What are the five most common words in sentences?

```{r}
str_split(sentences, boundary("word"))%>%
  unlist()%>%
  as_tibble()%>%
  mutate(value = str_to_lower(value))%>%
  count(value)%>%
  arrange(desc(n))
```

## Other uses of regular expressions
-- apropos() searches all objects available from the global environment
```{r}
apropos('filter')
```



Find the stringi functions that:
Count the number of words.
```{r}
stringi::stri_count_boundaries(sentences)
```
    
Find duplicated strings.
```{r}
stringi::stri_duplicated()
```
    
Generate random text.
```{r}
stri_rand_lipsum(2)
stri_rand_strings(1, 10)
```

How do you control the language that stri_sort() uses for sorting?
```{r}
#use the locale argument. can also use output from stri_opts_collator--which will give a locale, but also
# finer grained information
```

